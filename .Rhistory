Yhat_salary
Yhat_salary = (20*GPA) + (.07*IQ)+(35*GENDER)+(.01*GPA*IQ)+(-10*(GPA*GENDER))+50
Yhat_salary
print(Yhat_salary)
set.seed(1)
x1=runif (100)
x2=0.5*x1+rnorm (100)/10
y=2+2*x1+0.3*x2+rnorm (100)
cor(x1,x2)
plot(x1,x2)
lm(y~x1+x2)
print(lm(y~x1+x2))
summary(lm(y~x1+x2))
summary(lm(y~x1))
summary(lm(y~x2))
x1=c(x1, 0.1)
x2=c(x2, 0.8)
y=c(y,6)
summary(lm(y~x2))
summary(lm(y~x1+x2))
resid_matrix = matrix(rep(0,5000), nrow=1000)
for(i in 1:1000){
n = 100
x = rnorm(n)
y = 5 + 2 * x + rnorm(n, 0.5)
for(j in 1:5){
mat[i,j] = sum(residuals(lm(y ~ poly(x,j,raw=T)))^2)
}
}
for(i in 1:1000){
n = 100
x = rnorm(n)
y = 5 + 2 * x + rnorm(n, 0.5)
for(j in 1:5){
resid_matrix[i,j] = sum(residuals(lm(y ~ poly(x,j,raw=T)))^2)
}
}
resid_matrix
boxplot(resid_matrix)
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
library(knitr)
include_graphics('./Kaggle screen shot STTT 481.png')
include_graphics('./swirl_hw_1_Ex1.PNG')
include_graphics('./swirl_hw_1_Ex2.PNG')
include_graphics('./swirl_hw_1_Ex3.PNG')
include_graphics('./swirl_hw_1_Ex4.PNG')
include_graphics('./swirl_hw_1_Ex5.PNG')
include_graphics('./swirl_hw_1_Ex6.PNG')
include_graphics('./swirl_hw_1_Ex7.PNG')
include_graphics('./swirl_hw_1_Ex8.PNG')
include_graphics('./swirl_hw_1_Ex9.PNG')
include_graphics('./swirl_hw_1_Ex10.PNG')
include_graphics('./swirl_hw_1_Ex11.PNG')
include_graphics('./swirl_hw_1_Ex12.PNG')
include_graphics('./swirl_hw_1_Ex13.PNG')
include_graphics('./swirl_hw_1_Ex14.PNG')
include_graphics('./swirl_hw_1_Ex15.PNG')
#Let's first replicate the df in question #7 from section 2.4
X1 <- c(0,2,0,0,-1,1)
X2 <- c(3,0,1,1,0,1)
X3 <- c(0,0,3,2,1,1)
Y <- c("Red","Red","Red","Green","Green","Red")
training_data <- data.frame(X1,X2,X3,Y)
training_data
#(a)
college <- read.csv("College.csv",header = TRUE)
college
#(b)
#Look at data using fix()
fix(college)
#Try the following commands
rownames(college)=college[,1]
fix(college)
college
college=college[,-1]
fix(college)
#Display college, see row.names is set and that extra (prior) column is removed
college
#(c) i.
#Use summary function on data set 'college'
summary(college)
#(c) ii.
#Use pairs function to create scatterplot matrix of first 10 columns of data set 'college'
pairs(college[1:10])
#(c) iii.
boxplot(college$Outstate, college$Private)
#(c) iv.
#Creates a vector of "No"'s dependant on the number of rows in the table
Elite=rep("No",nrow(college))
#Sets the values with a percent of over 50% to be a string "Yes"
Elite[college$Top10perc>50]="Yes"
#Coded "Elite" as a factory (aka category or enumerated type)
Elite=as.factor(Elite)
#Adds 'Elite' column to data set 'college'
college <- data.frame(college ,Elite)
college
#Run summary function on cllege and ensure Eliste is contained
summary(college)
#Get Count of Elite Colleges
number_of_elite <- sum(college$Elite=="Yes")
#Get Percent of Colleges Elite
percent_of_elite <- number_of_elite / (length(college$Elite))
#Boxplot of Out of State vs. Elise
boxplot(college$Outstate,college$Elite)
#(c) v.
#Histograms for College$P.Undergrad
#Divide window into  2x2 matrix
par(mfrow=c(2,2))
#Produce 4 histograms with differing numbers of bins (designated by 'break' parameter)
hist(College$P.Undergrad, breaks= 2 )
hist(College$P.Undergrad, breaks= 6 )
hist(College$P.Undergrad, breaks= 9 )
hist(College$P.Undergrad, breaks= 45 )
#(c) v.
#Histograms for College$Room.Board
#Divide window into  2x2 matrix
par(mfrow=c(2,2))
#Produce 4 histograms with differing numbers of bins (designated by 'break' parameter)
hist(College$Room.Board, breaks= 2 )
hist(College$Room.Board, breaks= 6 )
hist(College$Room.Board, breaks= 9 )
hist(College$Room.Board, breaks= 45 )
#(c) v.
#Histograms for College$Books
#Divide window into  2x2 matrix
par(mfrow=c(2,2))
#Produce 4 histograms with differing numbers of bins (designated by 'break' parameter)
hist(College$Books, breaks= 2 )
hist(College$Books, breaks= 6 )
hist(College$Books, breaks= 9 )
hist(College$Books, breaks= 45 )
#(c) vi.
#This did not end up being useful as there are too many variables
pairs(College)
College_Private = College[College$Private == 'Yes',]
College_Public = College[College$Private == 'No',]
#Create histograms to compare college cost
par(mfrow=c(2,2))
hist(College_Private$Books)
hist(College_Public$Books)
hist(College_Private$Room.Board)
hist(College_Public$Room.Board)
#(c) vi.
avg_g_rate_priv <- mean(College_Private$Grad.Rate)
avg_g_rate_pub <- mean(College_Public$Grad.Rate)
t.test(College_Private$Grad.Rate,College_Public$Grad.Rate)
#9
#View data and remove columns with missing data points
Auto
#Removes any rows with a missing data point
Auto_rm <- na.omit(Auto)
Auto_rm
#View all variables using summary function
summary(Auto_rm)
#Create a vector of all the quantitative variables
quant_vars <- c("mpg","cylinders","displacement","horsepower","weight","acceleration")
#Create a vector of all the qualitative variables
qual_vars <- c("name","year","origin",NA,NA,NA)
#Create and display columns containing quant_vars and qual_vars (quantitative variables and qualitative variables respectively)
Variable_Type <- data.frame(quant_vars,qual_vars)
Variable_Type
#Calculates range of all quantitative variables variables
range(Auto_rm$mpg)
range(Auto_rm$cylinders)
range(Auto_rm$displacement)
range(Auto_rm$horsepower)
range(Auto_rm$weight)
range(Auto_rm$acceleration)
#(c)
#Calc mean and sd of mpg
mean(Auto_rm$mpg)
sd(Auto_rm$mpg)
#Calc mean and sd of cylinders
mean(Auto_rm$cylinders)
sd(Auto_rm$cylinders)
#Calc mean and sd of displacement
mean(Auto_rm$displacement)
sd(Auto_rm$displacement)
#Calc mean and sd of horsepower
mean(Auto_rm$horsepower)
sd(Auto_rm$horsepower)
#Calc mean and sd of weight
mean(Auto_rm$weight)
sd(Auto_rm$weight)
#Calc mean and sd of acceleration
mean(Auto_rm$acceleration)
sd(Auto_rm$acceleration)
#(d)
#Create  data set of rows 10 - 85 of 'Auto_rm'
Auto_rm2 <- Auto_rm[c(-10:-85),]
#Display new data set 'Auto_rm2'
Auto_rm2
#Returns means of key quantitative columns
colMeans(Auto_rm2[1:6])
sapply(Auto_rm2[1:6], sd)
sapply(Auto_rm2[1:6], range)
pairs(Auto_rm[1:6])
plot(lm(mpg~ ., data = Auto_rm[1:6]))
plot(lm(cylinders~ ., data = Auto_rm[1:6]))
plot(lm(displacement~ ., data = Auto_rm[1:6]))
plot(lm(horsepower~ ., data = Auto_rm[1:6]))
plot(lm(weight~ ., data = Auto_rm[1:6]))
plot(lm(acceleration~ ., data = Auto_rm[1:6]))
cor(Auto_rm[1:6])
cor(Auto_rm[1:6])>.75
#I created a heat map but it did not end up being useful
#heatmap(as.matrix(Auto_rm[1:6]), scale="column", col = cm.colors(256))
lm(mpg~.,data=Auto_rm[1:6])
summary(lm(mpg~.,data=Auto_rm[1:6]))
plot(lm(mpg~.,data=Auto_rm[1:6]))
IQ=110
GPA=4
GENDER=1
Yhat_salary = (20*GPA) + (.07*IQ)+(35*GENDER)+(.01*GPA*IQ)+(-10*(GPA*GENDER))+50
print(Yhat_salary)
resid_matrix = matrix(rep(0,5000), nrow=1000)
for(i in 1:1000){
n = 100
x = rnorm(n)
y = 5 + 2 * x + rnorm(n, 0.5)
for(j in 1:5){
resid_matrix[i,j] = sum(residuals(lm(y ~ poly(x,j,raw=T)))^2)
}
}
boxplot(resid_matrix)
#(a)
#Summarizes
summary(Auto_rm)
#Creates matrix of scatter plots containing all variables in data set
pairs(Auto_rm)
#(b)
#create matrix of correlations, excluding last name columns
pairs(cor(Auto_rm[1:8]))
model.lm1 <- lm(mpg~cylinders+displacement+horsepower+weight+acceleration+year+origin, data = Auto_rm)
summary(model.lm1)
plot(model.lm1)
model.lm2 <- lm(mpg~cylinders*displacement*horsepower*weight*acceleration*year*origin, data = Auto_rm)
summary(model.lm2)
#Model taking into account my intuition and prior knowledge of the data set
model.lm2 <- lm(mpg~cylinders+displacement+horsepower+weight+acceleration+year+origin+ year:mpg+year:horsepower, data = Auto_rm)
#Model taking into account my intuition and prior knowledge of the data set
model.lm3 <- lm(mpg~cylinders+displacement+horsepower+weight+acceleration+year+origin+ year:mpg+year:horsepower, data = Auto_rm)
summary(model.lm3)
model.lm2 <- lm(mpg~cylinders*displacement*horsepower*weight*acceleration*year*origin, data = Auto_rm)
summary(model.lm2)
model.lm3 <- lm(log(mpg)~cylinders+displacement+horsepower+weight+acceleration+year+origin, data = Auto_rm)
summary(model.lm3)
model.lm4 <- lm(sqrt(mpg)~cylinders+displacement+horsepower+weight+acceleration+year+origin, data = Auto_rm)
summary(model.lm4)
model.lm5 <- lm(mpg~cylinders+displacement+horsepower+weight+(acceleration*year)^2+origin, data = Auto_rm)
summary(model.lm5)
Carseats
Carseats_Model1 <- lm(Sales~Price+Urban+US, data = Carseats)
summary(Carseats_Model1)
Carseats
summary(Carseats_Model1)
Carseats_Model2 <- lm(Sales~Price+US, data = Carseats)
summary(Carseats_Model2)
confint(Carseats_Model2)
plot(Carseats_Model2)
set.seed(1)
x=rnorm (100)
y=2*x+rnorm (100)
lm(y~x)
lm(y~x - 1)
lm(y~x +0)
summary(lm(y~x +0))
summary(lm(y~x +0))
summary(lm(y~x))
t_new <- sqrt(n - 1)*(x %*% y)/sqrt(sum(x^2) * sum(y^2) - (x %*% y)^2)
t_new
summary(lm(y~x))
print(summary(lm(y~x)))
print(summary(lm(y~x)))
print(summary(lm(x~y)))
get(wd)
get(wd)getwd()
getwd()
setwd("C:/Users/sam/Desktop/STT481_Personal_Work")
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(car)
library(MASS)
knitr::opts_chunk$set(echo = TRUE)
library(car)
library(MASS)
#library(swirl)
#install_course("Regression_Models")
#swirl()
sat <- read.csv("sat.csv")
head(sat)
summary(sat)
SAT_Model1 <- lm(sat~expend+income+public+takers ,data=sat)
summary(SAT_Model1)
par(mfrow = c(2, 2))
plot(SAT_Model1)
#Display both plots at the same time
par(mfrow = c(1, 2))
#Create a QQ plot to see the root - standardized residuals
qqPlot(SAT_Model1, main="QQ Plot")
#Compute studentized residuals: Like standardized residuals, these are normalized to unit variance, but the Studentized version is fitted ignoring the current data point. (They are sometimes called jackknifed residuals).
sresid <- studres(SAT_Model1)
#Plot studentized residuals and compare how they fall in comparison to a normal distribution
hist(sresid, freq=FALSE,
main="Distribution of Studentized Residuals")
xfit<-seq(min(sresid),max(sresid),length=40)
yfit<-dnorm(xfit)
lines(xfit, yfit)
#Display 2 plots
par(mfrow = c(2, 2))
#added variable plots: These functions construct added-variable, also called partial-regression, plots for linear and generalized linear models
avPlots(SAT_Model1)
# Cook's D plot
#Set the cutoff value for Cook's Distance as : 4/(n-k-1)
cutoff <- 4/((nrow(sat)-length(SAT_Model1$coefficients)-2))
plot(SAT_Model1, which=4, cook.levels=cutoff)
# Influence Plot
influencePlot(SAT_Model1, id.method="identify", main="Influence Plot", sub="Circle size is proportial to Cook's Distance (Based on computed cutoff value)" )
#Find outliers, plot standardized residuals, find leverage points
outlierTest(SAT_Model1)
qqPlot(SAT_Model1, main="QQ Plot")
leveragePlots(SAT_Model1)
summary(SAT_Model1)
pairs(sat)
takers2 <- sat$takers^2
SAT_Model2 <- lm(sat~expend+income+public+takers2 ,data=sat)
plot(SAT_Model2)
summary(SAT_Model2)
probx <- (e^(-6+(.05*3.5)+3.5))/(1+e^(-6+(.05*3.5)+3.5))
probx <- (exp^(-6+(.05*3.5)+3.5))/(1+e^(-6+(.05*3.5)+3.5))
probx <- ((exp(1))^(-6+(.05*3.5)+3.5))/(1+(exp(1))^(-6+(.05*3.5)+3.5))
probx
probx <- ((exp(1))^(-6+(.05*40)+3.5))/(1+(exp(1))^(-6+(.05*40)+3.5))
probx
probx2 <- ((exp(1))^(-6+(.05*45)+3.5))/(1+(exp(1))^(-6+(.05*45)+3.5))
probx2 <- ((exp(1))^(-6+(.05*50)+3.5))/(1+(exp(1))^(-6+(.05*50)+3.5))
probx2
arthritis <- read.csv("arthritis.csv")
head(arthritis)
summary(arthritis)
arth_Model1 <- glm(Improved~Treatment+Sex+Age,data=arthritis,family = binomial)
summary(arth_Model1)
plot(arth_Model1)
#Find outliers, plot standardized residuals, find leverage points
outlierTest(SAT_Model1)
par(mfrow = c(2, 2))
qqPlot(SAT_Model1, main="QQ Plot")
leveragePlots(SAT_Model1)
arth_Model1 <- glm(Improved~Treatment+Sex+Age,data=arthritis,family = binomial)
par(mfrow = c(2, 2))
summary(arth_Model1)
plot(arth_Model1)
train.dat <- read.csv("zipcode_train.csv")
train.dat$Y <- as.factor(train.dat$Y)
test.dat <- read.csv("zipcode_test.csv")
test.dat$Y <- as.factor(test.dat$Y)
COLORS <- c("white", "black")
CUSTOM_COLORS <- colorRampPalette(colors = COLORS)
vis <- function(i){
par(pty = "s", mar = c(1, 1, 1, 1), xaxt = "n", yaxt = "n")
z <- matrix(as.numeric(train.dat[i,1:256]), 16, 16)
image(1:16,1:16,z[,16:1], col = CUSTOM_COLORS(256))
}
vis(2) # hand written 1 (from 1 to 1005)
vis(1500) # hand written 2 (from 1006 to 1736)
logit(1.7)
#Given treated and Ses and age held constant we predict a
exp(1.75980)
confint(arth_Model1)
arth_Model2 <- glm(Improved~Treatment+Sex+Age+Sex:Age,data=arthritis,family = binomial)
par(mfrow = c(2, 2))
summary(arth_Model2)
plot(arth_Model2)
arth_Model2 <- glm(Improved~Treatment+Sex+Age+Sex:Age,data=arthritis,family = binomial)
par(mfrow = c(2, 2))
summary(arth_Model2)
plot(arth_Model2)
weekly
Weekly
library(ISLR)
Weekly
pairs(Weekly)
hist(Weekly)
summary(Weekly)
pairs(Weekly)
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(car)
library(MASS)
sat <- read.csv("sat.csv")
head(sat)
summary(sat)
SAT_Model1 <- lm(sat~expend+income+public+takers ,data=sat)
summary(SAT_Model1)
par(mfrow = c(2, 2))
plot(SAT_Model1)
ncvTest(SAT_Model1)
plot(SAT_Model1,3)
#Display both plots at the same time
par(mfrow = c(1, 2))
#Create a QQ plot to see the root - standardized residuals
qqPlot(SAT_Model1, main="QQ Plot")
#Compute studentized residuals: Like standardized residuals, these are normalized to unit variance, but the Studentized version is fitted ignoring the current data point. (They are sometimes called jackknifed residuals).
sresid <- studres(SAT_Model1)
#Plot studentized residuals and compare how they fall in comparison to a normal distribution
hist(sresid, freq=FALSE,
main="Distribution of Studentized Residuals")
xfit<-seq(min(sresid),max(sresid),length=40)
yfit<-dnorm(xfit)
lines(xfit, yfit)
#Display 2 plots
par(mfrow = c(2, 2))
#added variable plots: These functions construct added-variable, also called partial-regression, plots for linear and generalized linear models
avPlots(SAT_Model1)
# Cook's D plot
#Set the cutoff value for Cook's Distance as : 4/(n-k-1)
cutoff <- 4/((nrow(sat)-length(SAT_Model1$coefficients)-2))
plot(SAT_Model1, which=4, cook.levels=cutoff)
# Influence Plot
influencePlot(SAT_Model1, id.method="identify", main="Influence Plot", sub="Circle size is proportial to Cook's Distance (Based on computed cutoff value)" )
#Find outliers, plot standardized residuals, find leverage points
outlierTest(SAT_Model1)
par(mfrow = c(2, 2))
qqPlot(SAT_Model1, main="QQ Plot")
leveragePlots(SAT_Model1)
summary(SAT_Model1)
pairs(sat)
takers2 <- sat$takers^2
SAT_Model2 <- lm(sat~expend+income+public+takers2 ,data=sat)
plot(SAT_Model2)
summary(SAT_Model2)
data_rm <- c(22, 29, 35,50)
takers2 <- sat$takers^2
SAT_Model2 <- lm(sat~expend+income+public+takers2 ,data=sat)
par(mfrow = c(2, 2))
plot(SAT_Model2)
summary(SAT_Model2)
data_rm <- c(22, 29, 35,50)
SAT_data2 <- sat[-data_rm]
SAT_Model3 <- lm(sat~expend+income+public+takers ,data=SAT_data2)
summary(SAT_Model3)
par(mfrow = c(2, 2))
plot(SAT_Model3)
#Display 2 plots
par(mfrow = c(2, 2))
#added variable plots: These functions construct added-variable, also called partial-regression, plots for linear and generalized linear models
avPlots(SAT_Model3)
# Cook's D plot
#Set the cutoff value for Cook's Distance as : 4/(n-k-1)
cutoff <- 4/((nrow(SAT_data2)-length(SAT_Model3$coefficients)-2))
plot(SAT_Model3, which=4, cook.levels=cutoff)
# Influence Plot
influencePlot(SAT_Model3, id.method="identify", main="Influence Plot", sub="Circle size is proportial to Cook's Distance (Based on computed cutoff value)" )
data_rm <- c(22, 29, 35,50)
SAT_data2 <- sat[-data_rm,]
SAT_Model3 <- lm(sat~expend+income+public+takers ,data=SAT_data2)
summary(SAT_Model3)
par(mfrow = c(2, 2))
plot(SAT_Model3)
#Display 2 plots
par(mfrow = c(2, 2))
#added variable plots: These functions construct added-variable, also called partial-regression, plots for linear and generalized linear models
avPlots(SAT_Model3)
# Cook's D plot
#Set the cutoff value for Cook's Distance as : 4/(n-k-1)
cutoff <- 4/((nrow(SAT_data2)-length(SAT_Model3$coefficients)-2))
plot(SAT_Model3, which=4, cook.levels=cutoff)
# Influence Plot
influencePlot(SAT_Model3, id.method="identify", main="Influence Plot", sub="Circle size is proportial to Cook's Distance (Based on computed cutoff value)" )
arthritis <- read.csv("arthritis.csv")
head(arthritis)
summary(arthritis)
arth_Model1 <- glm(Improved~Treatment+Sex+Age,data=arthritis,family = binomial)
par(mfrow = c(2, 2))
summary(arth_Model1)
plot(arth_Model1)
library(ISLR)
Weekly
pairs(Weekly)
summary(Weekly)
Weekly_Model1 <- lm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Weekly)
summary(Weekly_Model1)
Weekly_Model1 <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Weekly)
summary(Weekly_Model1)
Weekly_Model1 <- glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Weekly,family=binomial)
summary(Weekly_Model1)
library(caret)
confusionMatrix(Weekly_Model1)
confusionMatrix(Weekly)
probs <- predict(fit.glm, type = "response")
pred.glm <- rep("Down", length(probs))
table(pred.glm, Direction)
probs <- predict(fit.glm, type = "response")
probs <- predict(Weekly_Model1, type = "response")
pred.Weekly_Model1 <- rep("Down", length(probs))
probs <- predict(Weekly_Model1, type = "response")
pred.Weekly_Model1 <- rep("Down", length(probs))
pred.Weekly_Model1[probs > 0.5] <- "Up"
table(pred.Weekly_Model1, Direction)
table(pred.Weekly_Model1)
table(pred.Weekly_Model1, Direction(Weekly_Model1))
probs <- predict(Weekly_Model1, type = "response")
pred.Weekly_Model1 <- rep("Down", length(probs))
pred.Weekly_Model1[probs > 0.5] <- "Up"
Direction <- pred.Weekly_Model1,pred.Weekly_Model1[probs > 0.5]
Direction <- c(pred.Weekly_Model1,pred.Weekly_Model1[probs > 0.5]_
Direction <- c(pred.Weekly_Model1,pred.Weekly_Model1[probs > 0.5])
table(pred.Weekly_Model1, Direction)
table(pred.Weekly_Model1, Direction,data=Weekly)
table(pred.Weekly_Model1, Weekly_Model1$Direction)
